{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Credit Card Fraud Detection - Data Cleaning & EDA\n",
    "## Professional Data Cleaning Pipeline with ACTUAL Data Cleaning\n",
    "\n",
    "**Author:** Data Science Team  \n",
    "**Date:** February 2026  \n",
    "**Dataset:** Credit Card Transactions (10,000 records)\n",
    "\n",
    "---\n",
    "\n",
    "## ‡∏™‡∏¥‡πà‡∏á‡∏ó‡∏µ‡πà‡πÇ‡∏ô‡πâ‡∏ï‡∏ö‡∏∏‡πä‡∏Ñ‡∏ô‡∏µ‡πâ‡∏ó‡∏≥:\n",
    "1. ‚úÖ **‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•** (Data Quality Check)\n",
    "2. ‚úÖ **‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•** (Data Cleaning)\n",
    "   - ‡∏•‡∏ö/‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏Ñ‡πà‡∏≤‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á\n",
    "   - ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏Ñ‡πà‡∏≤ Outliers\n",
    "   - ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏Ñ‡πà‡∏≤ Missing (‡∏ñ‡πâ‡∏≤‡∏°‡∏µ)\n",
    "3. ‚úÖ **‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•** (EDA)\n",
    "4. ‚úÖ **‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏™‡∏∞‡∏≠‡∏≤‡∏î‡πÅ‡∏•‡πâ‡∏ß**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from scipy.stats import chi2_contingency, ks_2samp, mannwhitneyu\n",
    "import warnings\n",
    "import os\n",
    "from io import StringIO\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuration\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette(\"husl\")\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "print(\"‚úì Libraries imported successfully\")\n",
    "print(\"‚úì Configuration set\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define file paths\n",
    "input_filepath = 'Raw_Data/credit_card_fraud_10k.csv'\n",
    "output_filepath = 'Cleaned_Data/credit_card_fraud_10k_cleaned.csv'\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "output_dir = os.path.dirname(output_filepath)\n",
    "if output_dir and not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "    print(f\"‚úì Created output directory: {output_dir}\")\n",
    "\n",
    "# Load data\n",
    "print(f\"Loading data from: {input_filepath}\")\n",
    "df_raw = pd.read_csv(input_filepath)\n",
    "print(f\"‚úì Loaded {len(df_raw)} records from file\")\n",
    "print(\"=\"*80)\n",
    "print(\"FRAUD DETECTION DATA PIPELINE - INITIALIZED\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Create a copy for cleaning\n",
    "df = df_raw.copy()\n",
    "print(f\"\\n‚úì Created working copy of data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Quality Assessment (BEFORE Cleaning)\n",
    "### Step 1: Schema Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n[STEP 1] SCHEMA VALIDATION\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "expected_schema = {\n",
    "    'transaction_id': 'int64',\n",
    "    'amount': 'float64',\n",
    "    'transaction_hour': 'int64',\n",
    "    'merchant_category': 'object',\n",
    "    'foreign_transaction': 'int64',\n",
    "    'location_mismatch': 'int64',\n",
    "    'device_trust_score': 'int64',\n",
    "    'velocity_last_24h': 'int64',\n",
    "    'cardholder_age': 'int64',\n",
    "    'is_fraud': 'int64'\n",
    "}\n",
    "\n",
    "schema_valid = True\n",
    "for col, dtype in expected_schema.items():\n",
    "    if col not in df.columns:\n",
    "        print(f\"  ‚úó Missing column: {col}\")\n",
    "        schema_valid = False\n",
    "    elif df[col].dtype != dtype:\n",
    "        print(f\"  ‚ö† Column {col}: Expected {dtype}, got {df[col].dtype}\")\n",
    "\n",
    "if schema_valid:\n",
    "    print(\"  ‚úì Schema validation PASSED\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Missing Value Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n[STEP 2] MISSING VALUE ANALYSIS\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "missing_summary = pd.DataFrame({\n",
    "    'Column': df.columns,\n",
    "    'Missing_Count': df.isnull().sum().values,\n",
    "    'Missing_Percentage': (df.isnull().sum() / len(df) * 100).values,\n",
    "    'Data_Type': df.dtypes.values\n",
    "})\n",
    "\n",
    "print(missing_summary.to_string(index=False))\n",
    "\n",
    "total_missing = df.isnull().sum().sum()\n",
    "if total_missing == 0:\n",
    "    print(\"\\n  ‚úì No missing values detected\")\n",
    "else:\n",
    "    print(f\"\\n  ‚ö† Total missing values: {total_missing}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Duplicate Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n[STEP 3] DUPLICATE DETECTION\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "# Check duplicate rows\n",
    "duplicate_rows = df.duplicated()\n",
    "dup_count = duplicate_rows.sum()\n",
    "\n",
    "# Check duplicate transaction IDs\n",
    "dup_ids = df['transaction_id'].duplicated()\n",
    "dup_id_count = dup_ids.sum()\n",
    "\n",
    "print(f\"  Duplicate Rows: {dup_count} ({dup_count/len(df)*100:.2f}%)\")\n",
    "print(f\"  Duplicate Transaction IDs: {dup_id_count}\")\n",
    "\n",
    "if dup_count > 0:\n",
    "    print(\"\\n  Duplicate Records:\")\n",
    "    print(df[duplicate_rows])\n",
    "else:\n",
    "    print(\"\\n  ‚úì No duplicates detected\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Domain Constraint Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n[STEP 4] DOMAIN CONSTRAINT VALIDATION (BEFORE CLEANING)\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "validation_results = {}\n",
    "\n",
    "# Transaction Hour: 0-23\n",
    "invalid_hours = df[(df['transaction_hour'] < 0) | (df['transaction_hour'] > 23)]\n",
    "validation_results['transaction_hour'] = len(invalid_hours)\n",
    "print(f\"  transaction_hour (0-23): {len(invalid_hours)} invalid values\")\n",
    "if len(invalid_hours) > 0:\n",
    "    print(f\"    ‚Üí Invalid values: {invalid_hours['transaction_hour'].unique()}\")\n",
    "\n",
    "# Device Trust Score: 0-100\n",
    "invalid_scores = df[(df['device_trust_score'] < 0) | (df['device_trust_score'] > 100)]\n",
    "validation_results['device_trust_score'] = len(invalid_scores)\n",
    "print(f\"  device_trust_score (0-100): {len(invalid_scores)} invalid values\")\n",
    "if len(invalid_scores) > 0:\n",
    "    print(f\"    ‚Üí Invalid values: {invalid_scores['device_trust_score'].unique()}\")\n",
    "\n",
    "# Amount: positive\n",
    "invalid_amounts = df[df['amount'] <= 0]\n",
    "validation_results['amount'] = len(invalid_amounts)\n",
    "print(f\"  amount (>0): {len(invalid_amounts)} invalid values\")\n",
    "if len(invalid_amounts) > 0:\n",
    "    print(f\"    ‚Üí Invalid transaction IDs: {invalid_amounts['transaction_id'].tolist()}\")\n",
    "    print(f\"    ‚Üí Invalid amounts: {invalid_amounts['amount'].tolist()}\")\n",
    "\n",
    "# Velocity: non-negative\n",
    "invalid_velocity = df[df['velocity_last_24h'] < 0]\n",
    "validation_results['velocity'] = len(invalid_velocity)\n",
    "print(f\"  velocity_last_24h (‚â•0): {len(invalid_velocity)} invalid values\")\n",
    "if len(invalid_velocity) > 0:\n",
    "    print(f\"    ‚Üí Invalid values: {invalid_velocity['velocity_last_24h'].unique()}\")\n",
    "\n",
    "# Age: reasonable range\n",
    "invalid_age = df[(df['cardholder_age'] < 18) | (df['cardholder_age'] > 100)]\n",
    "validation_results['cardholder_age'] = len(invalid_age)\n",
    "print(f\"  cardholder_age (18-100): {len(invalid_age)} invalid values\")\n",
    "if len(invalid_age) > 0:\n",
    "    print(f\"    ‚Üí Invalid values: {invalid_age['cardholder_age'].unique()}\")\n",
    "\n",
    "# Binary fields: 0 or 1\n",
    "binary_fields = ['foreign_transaction', 'location_mismatch', 'is_fraud']\n",
    "for field in binary_fields:\n",
    "    invalid_binary = df[~df[field].isin([0, 1])]\n",
    "    validation_results[field] = len(invalid_binary)\n",
    "    print(f\"  {field} (0/1): {len(invalid_binary)} invalid values\")\n",
    "    if len(invalid_binary) > 0:\n",
    "        print(f\"    ‚Üí Invalid values: {invalid_binary[field].unique()}\")\n",
    "\n",
    "total_invalid = sum(validation_results.values())\n",
    "if total_invalid == 0:\n",
    "    print(\"\\n  ‚úì All domain constraints satisfied\")\n",
    "else:\n",
    "    print(f\"\\n  ‚ö† Total domain violations: {total_invalid}\")\n",
    "    print(f\"  ‚Üí These will be CLEANED in the next steps\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Outlier Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n[STEP 5] OUTLIER DETECTION (BEFORE CLEANING)\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "numerical_features = ['amount', 'transaction_hour', 'device_trust_score', \n",
    "                     'velocity_last_24h', 'cardholder_age']\n",
    "\n",
    "outlier_summary = []\n",
    "\n",
    "for feature in numerical_features:\n",
    "    # IQR Method\n",
    "    Q1 = df[feature].quantile(0.25)\n",
    "    Q3 = df[feature].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    \n",
    "    iqr_outliers = df[(df[feature] < lower_bound) | (df[feature] > upper_bound)]\n",
    "    \n",
    "    # Z-Score Method (threshold = 3)\n",
    "    z_scores = np.abs(stats.zscore(df[feature]))\n",
    "    z_outliers = df[z_scores > 3]\n",
    "    \n",
    "    outlier_summary.append({\n",
    "        'Feature': feature,\n",
    "        'IQR_Outliers': len(iqr_outliers),\n",
    "        'Z_Score_Outliers': len(z_outliers),\n",
    "        'Lower_Bound': lower_bound,\n",
    "        'Upper_Bound': upper_bound,\n",
    "        'Min': df[feature].min(),\n",
    "        'Max': df[feature].max()\n",
    "    })\n",
    "\n",
    "outlier_df = pd.DataFrame(outlier_summary)\n",
    "print(outlier_df.to_string(index=False))\n",
    "print(\"\\n  Note: Outliers in fraud detection are often IMPORTANT (fraud cases)\")\n",
    "print(\"        We will keep them unless they are clearly data errors\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. üßπ DATA CLEANING (‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î‡∏à‡∏£‡∏¥‡∏á‡πÜ)\n",
    "### ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡∏Å‡∏≤‡∏£ Clean ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üßπ DATA CLEANING PROCESS (‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏£‡∏¥‡∏á)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "rows_before = len(df)\n",
    "cleaning_log = []\n",
    "\n",
    "print(f\"\\nStarting with: {rows_before} records\")\n",
    "print(\"\\nCleaning steps:\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean 1: Remove/Fix Invalid Amounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n[CLEAN 1] Handling Invalid Amounts (amount <= 0)\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "invalid_amounts = df[df['amount'] <= 0]\n",
    "print(f\"  Found {len(invalid_amounts)} records with invalid amounts\")\n",
    "\n",
    "if len(invalid_amounts) > 0:\n",
    "    print(f\"\\n  Invalid records:\")\n",
    "    print(invalid_amounts[['transaction_id', 'amount', 'is_fraud']].to_string(index=False))\n",
    "    \n",
    "    # Decision: Remove these records (can't have transactions with zero/negative amounts)\n",
    "    df = df[df['amount'] > 0]\n",
    "    \n",
    "    removed = len(invalid_amounts)\n",
    "    print(f\"\\n  ‚úì Removed {removed} records with invalid amounts\")\n",
    "    cleaning_log.append(f\"Removed {removed} records: amount <= 0\")\n",
    "else:\n",
    "    print(\"  ‚úì No invalid amounts found\")\n",
    "\n",
    "print(f\"\\n  Records after cleaning: {len(df)} (removed: {rows_before - len(df)})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean 2: Remove Duplicates (if any)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n[CLEAN 2] Removing Duplicate Records\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "rows_before_dedup = len(df)\n",
    "df_before_dedup = df.copy()\n",
    "\n",
    "# Remove duplicate rows (keep first occurrence)\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "duplicates_removed = rows_before_dedup - len(df)\n",
    "if duplicates_removed > 0:\n",
    "    print(f\"  ‚úì Removed {duplicates_removed} duplicate records\")\n",
    "    cleaning_log.append(f\"Removed {duplicates_removed} duplicate records\")\n",
    "else:\n",
    "    print(\"  ‚úì No duplicates found\")\n",
    "\n",
    "# Check for duplicate transaction IDs\n",
    "dup_ids = df['transaction_id'].duplicated()\n",
    "if dup_ids.sum() > 0:\n",
    "    print(f\"\\n  ‚ö† Warning: {dup_ids.sum()} duplicate transaction IDs still exist\")\n",
    "    print(\"  ‚Üí Removing records with duplicate transaction IDs (keeping first)\")\n",
    "    df = df.drop_duplicates(subset=['transaction_id'], keep='first')\n",
    "    print(f\"  ‚úì Cleaned duplicate IDs\")\n",
    "    cleaning_log.append(f\"Removed duplicate transaction IDs\")\n",
    "\n",
    "print(f\"\\n  Records after deduplication: {len(df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean 3: Fix Domain Violations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n[CLEAN 3] Fixing Domain Constraint Violations\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "rows_before_domain = len(df)\n",
    "\n",
    "# Transaction Hour: clip to 0-23\n",
    "invalid_hours = df[(df['transaction_hour'] < 0) | (df['transaction_hour'] > 23)]\n",
    "if len(invalid_hours) > 0:\n",
    "    print(f\"  ‚ö† Found {len(invalid_hours)} invalid transaction hours\")\n",
    "    df['transaction_hour'] = df['transaction_hour'].clip(0, 23)\n",
    "    print(f\"  ‚úì Clipped transaction_hour to valid range [0-23]\")\n",
    "    cleaning_log.append(f\"Clipped {len(invalid_hours)} transaction_hour values\")\n",
    "\n",
    "# Device Trust Score: clip to 0-100\n",
    "invalid_scores = df[(df['device_trust_score'] < 0) | (df['device_trust_score'] > 100)]\n",
    "if len(invalid_scores) > 0:\n",
    "    print(f\"  ‚ö† Found {len(invalid_scores)} invalid device trust scores\")\n",
    "    df['device_trust_score'] = df['device_trust_score'].clip(0, 100)\n",
    "    print(f\"  ‚úì Clipped device_trust_score to valid range [0-100]\")\n",
    "    cleaning_log.append(f\"Clipped {len(invalid_scores)} device_trust_score values\")\n",
    "\n",
    "# Velocity: clip to non-negative\n",
    "invalid_velocity = df[df['velocity_last_24h'] < 0]\n",
    "if len(invalid_velocity) > 0:\n",
    "    print(f\"  ‚ö† Found {len(invalid_velocity)} negative velocity values\")\n",
    "    df['velocity_last_24h'] = df['velocity_last_24h'].clip(lower=0)\n",
    "    print(f\"  ‚úì Clipped velocity_last_24h to non-negative\")\n",
    "    cleaning_log.append(f\"Clipped {len(invalid_velocity)} velocity_last_24h values\")\n",
    "\n",
    "# Age: Remove records with invalid ages (can't fix age easily)\n",
    "invalid_age = df[(df['cardholder_age'] < 18) | (df['cardholder_age'] > 100)]\n",
    "if len(invalid_age) > 0:\n",
    "    print(f\"  ‚ö† Found {len(invalid_age)} invalid ages\")\n",
    "    df = df[(df['cardholder_age'] >= 18) & (df['cardholder_age'] <= 100)]\n",
    "    print(f\"  ‚úì Removed {len(invalid_age)} records with invalid ages\")\n",
    "    cleaning_log.append(f\"Removed {len(invalid_age)} records: invalid age\")\n",
    "\n",
    "# Binary fields: Remove records with invalid binary values\n",
    "binary_fields = ['foreign_transaction', 'location_mismatch', 'is_fraud']\n",
    "for field in binary_fields:\n",
    "    invalid_binary = df[~df[field].isin([0, 1])]\n",
    "    if len(invalid_binary) > 0:\n",
    "        print(f\"  ‚ö† Found {len(invalid_binary)} invalid {field} values\")\n",
    "        df = df[df[field].isin([0, 1])]\n",
    "        print(f\"  ‚úì Removed {len(invalid_binary)} records with invalid {field}\")\n",
    "        cleaning_log.append(f\"Removed {len(invalid_binary)} records: invalid {field}\")\n",
    "\n",
    "domain_removed = rows_before_domain - len(df)\n",
    "if domain_removed == 0:\n",
    "    print(\"\\n  ‚úì No domain violations needed cleaning\")\n",
    "else:\n",
    "    print(f\"\\n  Total records removed for domain violations: {domain_removed}\")\n",
    "\n",
    "print(f\"\\n  Records after domain cleaning: {len(df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean 4: Handle Missing Values (if any found)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n[CLEAN 4] Handling Missing Values\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "missing_before = df.isnull().sum().sum()\n",
    "\n",
    "if missing_before > 0:\n",
    "    print(f\"  Found {missing_before} missing values\")\n",
    "    print(\"\\n  Missing value distribution:\")\n",
    "    print(df.isnull().sum()[df.isnull().sum() > 0])\n",
    "    \n",
    "    # Strategy: Remove rows with ANY missing values (for fraud detection, we need complete data)\n",
    "    rows_with_missing = df.isnull().any(axis=1).sum()\n",
    "    df = df.dropna()\n",
    "    \n",
    "    print(f\"\\n  ‚úì Removed {rows_with_missing} rows with missing values\")\n",
    "    cleaning_log.append(f\"Removed {rows_with_missing} rows with missing values\")\n",
    "else:\n",
    "    print(\"  ‚úì No missing values found\")\n",
    "\n",
    "print(f\"\\n  Records after missing value handling: {len(df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean 5: Reset Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n[CLEAN 5] Resetting Index\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "df = df.reset_index(drop=True)\n",
    "print(\"  ‚úì Index reset to sequential order\")\n",
    "print(f\"\\n  Final cleaned dataset: {len(df)} records\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üßπ DATA CLEANING SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\nOriginal dataset:    {rows_before:,} records\")\n",
    "print(f\"Cleaned dataset:     {len(df):,} records\")\n",
    "print(f\"Records removed:     {rows_before - len(df):,} ({(rows_before - len(df))/rows_before*100:.2f}%)\")\n",
    "print(f\"Records retained:    {len(df)/rows_before*100:.2f}%\")\n",
    "\n",
    "print(\"\\nCleaning actions performed:\")\n",
    "if cleaning_log:\n",
    "    for i, action in enumerate(cleaning_log, 1):\n",
    "        print(f\"  {i}. {action}\")\n",
    "else:\n",
    "    print(\"  ‚úì No cleaning needed - data was already clean\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Data Quality Assessment (AFTER Cleaning)\n",
    "### Verify Domain Constraints Again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n[VERIFICATION] DOMAIN CONSTRAINT VALIDATION (AFTER CLEANING)\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "verification_results = {}\n",
    "\n",
    "# Transaction Hour: 0-23\n",
    "invalid_hours = df[(df['transaction_hour'] < 0) | (df['transaction_hour'] > 23)]\n",
    "verification_results['transaction_hour'] = len(invalid_hours)\n",
    "print(f\"  transaction_hour (0-23): {len(invalid_hours)} invalid values {'‚úì' if len(invalid_hours)==0 else '‚úó'}\")\n",
    "\n",
    "# Device Trust Score: 0-100\n",
    "invalid_scores = df[(df['device_trust_score'] < 0) | (df['device_trust_score'] > 100)]\n",
    "verification_results['device_trust_score'] = len(invalid_scores)\n",
    "print(f\"  device_trust_score (0-100): {len(invalid_scores)} invalid values {'‚úì' if len(invalid_scores)==0 else '‚úó'}\")\n",
    "\n",
    "# Amount: positive\n",
    "invalid_amounts = df[df['amount'] <= 0]\n",
    "verification_results['amount'] = len(invalid_amounts)\n",
    "print(f\"  amount (>0): {len(invalid_amounts)} invalid values {'‚úì' if len(invalid_amounts)==0 else '‚úó'}\")\n",
    "\n",
    "# Velocity: non-negative\n",
    "invalid_velocity = df[df['velocity_last_24h'] < 0]\n",
    "verification_results['velocity'] = len(invalid_velocity)\n",
    "print(f\"  velocity_last_24h (‚â•0): {len(invalid_velocity)} invalid values {'‚úì' if len(invalid_velocity)==0 else '‚úó'}\")\n",
    "\n",
    "# Age: reasonable range\n",
    "invalid_age = df[(df['cardholder_age'] < 18) | (df['cardholder_age'] > 100)]\n",
    "verification_results['cardholder_age'] = len(invalid_age)\n",
    "print(f\"  cardholder_age (18-100): {len(invalid_age)} invalid values {'‚úì' if len(invalid_age)==0 else '‚úó'}\")\n",
    "\n",
    "# Binary fields: 0 or 1\n",
    "binary_fields = ['foreign_transaction', 'location_mismatch', 'is_fraud']\n",
    "for field in binary_fields:\n",
    "    invalid_binary = df[~df[field].isin([0, 1])]\n",
    "    verification_results[field] = len(invalid_binary)\n",
    "    print(f\"  {field} (0/1): {len(invalid_binary)} invalid values {'‚úì' if len(invalid_binary)==0 else '‚úó'}\")\n",
    "\n",
    "total_invalid = sum(verification_results.values())\n",
    "if total_invalid == 0:\n",
    "    print(\"\\n  ‚úÖ All domain constraints satisfied - DATA IS CLEAN!\")\n",
    "else:\n",
    "    print(f\"\\n  ‚ùå Total domain violations: {total_invalid} - CLEANING FAILED!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistical Profiling (Cleaned Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n[STEP 6] STATISTICAL PROFILING (CLEANED DATA)\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "numerical_features = ['amount', 'transaction_hour', 'device_trust_score', \n",
    "                     'velocity_last_24h', 'cardholder_age']\n",
    "\n",
    "stats_profile = df[numerical_features].describe(\n",
    "    percentiles=[.01, .05, .25, .5, .75, .95, .99]\n",
    ").T\n",
    "\n",
    "# Add additional statistics\n",
    "stats_profile['skewness'] = df[numerical_features].skew()\n",
    "stats_profile['kurtosis'] = df[numerical_features].kurtosis()\n",
    "stats_profile['cv'] = stats_profile['std'] / stats_profile['mean']\n",
    "\n",
    "print(\"\\nNumerical Features Profile:\")\n",
    "print(stats_profile.round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Target Variable Analysis (Cleaned Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n[STEP 7] TARGET VARIABLE ANALYSIS (CLEANED DATA)\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "fraud_dist = df['is_fraud'].value_counts().sort_index()\n",
    "fraud_pct = df['is_fraud'].value_counts(normalize=True).sort_index() * 100\n",
    "\n",
    "print(\"\\nTarget Variable Distribution:\")\n",
    "print(f\"  Normal (0): {fraud_dist.get(0, 0)} ({fraud_pct.get(0, 0):.2f}%)\")\n",
    "print(f\"  Fraud (1):  {fraud_dist.get(1, 0)} ({fraud_pct.get(1, 0):.2f}%)\")\n",
    "\n",
    "if 1 in fraud_dist.index and 0 in fraud_dist.index:\n",
    "    imbalance_ratio = fraud_dist[0] / fraud_dist[1]\n",
    "    print(f\"\\n  Imbalance Ratio: {imbalance_ratio:.2f}:1\")\n",
    "    \n",
    "    if imbalance_ratio > 10:\n",
    "        print(\"  ‚ö† HIGH IMBALANCE - Consider resampling techniques\")\n",
    "    elif imbalance_ratio > 5:\n",
    "        print(\"  ‚ö† MODERATE IMBALANCE - Monitor model performance\")\n",
    "    else:\n",
    "        print(\"  ‚úì ACCEPTABLE BALANCE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation Analysis (Cleaned Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n[STEP 9] CORRELATION ANALYSIS (CLEANED DATA)\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "numerical_cols = ['amount', 'transaction_hour', 'device_trust_score', \n",
    "                 'velocity_last_24h', 'cardholder_age', \n",
    "                 'foreign_transaction', 'location_mismatch', 'is_fraud']\n",
    "\n",
    "corr_matrix = df[numerical_cols].corr()\n",
    "\n",
    "print(\"\\nCorrelation with Target Variable (is_fraud):\")\n",
    "target_corr = corr_matrix['is_fraud'].sort_values(ascending=False)\n",
    "for feature, corr_val in target_corr.items():\n",
    "    if feature != 'is_fraud':\n",
    "        print(f\"  {feature:25s}: {corr_val:7.4f}\")\n",
    "\n",
    "# High correlations between features\n",
    "print(\"\\nHigh Feature Correlations (|r| > 0.7):\")\n",
    "high_corr_pairs = []\n",
    "for i in range(len(corr_matrix.columns)):\n",
    "    for j in range(i+1, len(corr_matrix.columns)):\n",
    "        if abs(corr_matrix.iloc[i, j]) > 0.7:\n",
    "            high_corr_pairs.append((\n",
    "                corr_matrix.columns[i],\n",
    "                corr_matrix.columns[j],\n",
    "                corr_matrix.iloc[i, j]\n",
    "            ))\n",
    "\n",
    "if high_corr_pairs:\n",
    "    for feat1, feat2, corr_val in high_corr_pairs:\n",
    "        print(f\"  {feat1} <-> {feat2}: {corr_val:.4f}\")\n",
    "else:\n",
    "    print(\"  ‚úì No multicollinearity detected\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Data Quality Report (Final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üìä FINAL DATA QUALITY SCORECARD\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "total_records = len(df)\n",
    "total_features = len(df.columns) - 1\n",
    "\n",
    "# Calculate quality score\n",
    "missing_values = df.isnull().sum().sum()\n",
    "duplicates = df.duplicated().sum()\n",
    "domain_violations = sum(verification_results.values())\n",
    "\n",
    "quality_scores = {\n",
    "    'Completeness': 100 if missing_values == 0 else \n",
    "                  (1 - missing_values / (total_records * total_features)) * 100,\n",
    "    'Uniqueness': 100 if duplicates == 0 else\n",
    "                 (1 - duplicates / total_records) * 100,\n",
    "    'Validity': 100 if domain_violations == 0 else 0,\n",
    "}\n",
    "\n",
    "overall_quality = np.mean(list(quality_scores.values()))\n",
    "\n",
    "print(f\"\\nDataset Size: {total_records} records √ó {total_features + 1} features\")\n",
    "print(f\"\\nQuality Dimensions:\")\n",
    "for dimension, score in quality_scores.items():\n",
    "    status = \"‚úì\" if score >= 95 else \"‚ö†\"\n",
    "    print(f\"  {status} {dimension:15s}: {score:6.2f}%\")\n",
    "\n",
    "print(f\"\\n{'='*40}\")\n",
    "print(f\"  Overall Quality Score: {overall_quality:.2f}%\")\n",
    "print(f\"{'='*40}\")\n",
    "\n",
    "# Quality grade\n",
    "if overall_quality >= 95:\n",
    "    grade = \"EXCELLENT ‚≠ê‚≠ê‚≠ê\"\n",
    "elif overall_quality >= 85:\n",
    "    grade = \"GOOD ‚≠ê‚≠ê\"\n",
    "elif overall_quality >= 70:\n",
    "    grade = \"FAIR ‚≠ê\"\n",
    "else:\n",
    "    grade = \"POOR ‚ö†\"\n",
    "\n",
    "print(f\"\\n  Data Quality Grade: {grade}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Exploratory Data Analysis (Cleaned Data)\n",
    "### Univariate Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"UNIVARIATE ANALYSIS (CLEANED DATA)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "numerical_features = ['amount', 'transaction_hour', 'device_trust_score', \n",
    "                     'velocity_last_24h', 'cardholder_age']\n",
    "\n",
    "for feature in numerical_features:\n",
    "    print(f\"\\n{feature.upper()}\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    print(f\"  Mean:       {df[feature].mean():.2f}\")\n",
    "    print(f\"  Median:     {df[feature].median():.2f}\")\n",
    "    print(f\"  Std Dev:    {df[feature].std():.2f}\")\n",
    "    print(f\"  Range:      [{df[feature].min():.2f}, {df[feature].max():.2f}]\")\n",
    "    print(f\"  IQR:        {df[feature].quantile(0.75) - df[feature].quantile(0.25):.2f}\")\n",
    "    \n",
    "    skew = df[feature].skew()\n",
    "    kurt = df[feature].kurtosis()\n",
    "    print(f\"  Skewness:   {skew:.3f} {'(Right-skewed)' if skew > 0 else '(Left-skewed)' if skew < 0 else '(Symmetric)'}\")\n",
    "    print(f\"  Kurtosis:   {kurt:.3f} {'(Heavy-tailed)' if kurt > 0 else '(Light-tailed)'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bivariate Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"BIVARIATE ANALYSIS (Features vs Fraud) - CLEANED DATA\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "if df['is_fraud'].nunique() < 2:\n",
    "    print(\"\\n  ‚ö† Cannot perform bivariate analysis - only one class present\")\n",
    "else:\n",
    "    numerical_features = ['amount', 'transaction_hour', 'device_trust_score', \n",
    "                         'velocity_last_24h', 'cardholder_age']\n",
    "    \n",
    "    for feature in numerical_features:\n",
    "        print(f\"\\n{feature.upper()} by Fraud Status:\")\n",
    "        print(\"-\" * 40)\n",
    "        \n",
    "        fraud_stats = df.groupby('is_fraud')[feature].describe()\n",
    "        print(fraud_stats)\n",
    "        \n",
    "        normal_vals = df[df['is_fraud'] == 0][feature]\n",
    "        fraud_vals = df[df['is_fraud'] == 1][feature]\n",
    "        \n",
    "        if len(fraud_vals) > 0:\n",
    "            stat, p_value = mannwhitneyu(normal_vals, fraud_vals)\n",
    "            print(f\"\\n  Mann-Whitney U test p-value: {p_value:.4f}\")\n",
    "            if p_value < 0.05:\n",
    "                print(f\"  ‚úì Significant difference between groups\")\n",
    "            else:\n",
    "                print(f\"  ‚úó No significant difference\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Save Cleaned Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üíæ SAVING CLEANED DATA\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Save cleaned data\n",
    "df.to_csv(output_filepath, index=False)\n",
    "print(f\"\\n‚úÖ Cleaned data saved to: {output_filepath}\")\n",
    "print(f\"‚úÖ Total records saved: {len(df):,}\")\n",
    "print(f\"‚úÖ Total features: {len(df.columns)}\")\n",
    "\n",
    "# File size\n",
    "import os\n",
    "file_size = os.path.getsize(output_filepath) / 1024  # KB\n",
    "print(f\"‚úÖ File size: {file_size:.2f} KB\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"EXECUTIVE SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\n‚úÖ Data Cleaning Completed\")\n",
    "print(f\"‚úÖ Exploratory Data Analysis Completed\")\n",
    "print(f\"‚úÖ Data Quality Score: {overall_quality:.2f}%\")\n",
    "print(f\"‚úÖ Records: {rows_before:,} ‚Üí {len(df):,} ({len(df)/rows_before*100:.2f}% retained)\")\n",
    "print(f\"‚úÖ Ready for Feature Engineering & Modeling\")\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Data Comparison: Before vs After Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üìä BEFORE vs AFTER CLEANING COMPARISON\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "comparison = pd.DataFrame({\n",
    "    'Metric': [\n",
    "        'Total Records',\n",
    "        'Missing Values',\n",
    "        'Duplicates',\n",
    "        'Invalid Amounts',\n",
    "        'Domain Violations',\n",
    "        'Data Quality Score'\n",
    "    ],\n",
    "    'Before Cleaning': [\n",
    "        f\"{rows_before:,}\",\n",
    "        f\"{df_raw.isnull().sum().sum()}\",\n",
    "        f\"{df_raw.duplicated().sum()}\",\n",
    "        f\"{len(df_raw[df_raw['amount'] <= 0])}\",\n",
    "        f\"{total_invalid}\",\n",
    "        \"98.33%\"  # From original output\n",
    "    ],\n",
    "    'After Cleaning': [\n",
    "        f\"{len(df):,}\",\n",
    "        f\"{df.isnull().sum().sum()}\",\n",
    "        f\"{df.duplicated().sum()}\",\n",
    "        f\"{len(df[df['amount'] <= 0])}\",\n",
    "        f\"{sum(verification_results.values())}\",\n",
    "        f\"{overall_quality:.2f}%\"\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(\"\\n\" + comparison.to_string(index=False))\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Quick Data Preview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nüìã CLEANED DATA PREVIEW\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nFirst 10 rows:\")\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nüìã DATA INFO\")\n",
    "print(\"=\"*80)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nüìã STATISTICAL SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "df.describe()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
