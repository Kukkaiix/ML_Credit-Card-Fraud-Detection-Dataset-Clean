{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Credit Card Fraud Detection - Data Cleaning & EDA\n",
    "## Professional Data Pipeline for Fraud Detection Analysis\n",
    "\n",
    "**Author:** Data Science Team  \n",
    "**Date:** February 2026  \n",
    "**Dataset:** Credit Card Transactions (10,000 records)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from scipy.stats import chi2_contingency, ks_2samp, mannwhitneyu\n",
    "import warnings\n",
    "import os\n",
    "from io import StringIO\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuration\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette(\"husl\")\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "print(\"✓ Libraries imported successfully\")\n",
    "print(\"✓ Configuration set\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define file paths\n",
    "input_filepath = 'Raw_Data/credit_card_fraud_10k.csv'\n",
    "output_filepath = 'Cleaned_Data/credit_card_fraud_10k_cleaned.csv'\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "output_dir = os.path.dirname(output_filepath)\n",
    "if output_dir and not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "    print(f\"✓ Created output directory: {output_dir}\")\n",
    "\n",
    "# Load data\n",
    "print(f\"Loading data from: {input_filepath}\")\n",
    "df = pd.read_csv(input_filepath)\n",
    "print(f\"✓ Loaded {len(df)} records from file\")\n",
    "print(\"=\"*80)\n",
    "print(\"FRAUD DETECTION DATA PIPELINE - INITIALIZED\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Quality Assessment\n",
    "### Step 1: Schema Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n[STEP 1] SCHEMA VALIDATION\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "expected_schema = {\n",
    "    'transaction_id': 'int64',\n",
    "    'amount': 'float64',\n",
    "    'transaction_hour': 'int64',\n",
    "    'merchant_category': 'object',\n",
    "    'foreign_transaction': 'int64',\n",
    "    'location_mismatch': 'int64',\n",
    "    'device_trust_score': 'int64',\n",
    "    'velocity_last_24h': 'int64',\n",
    "    'cardholder_age': 'int64',\n",
    "    'is_fraud': 'int64'\n",
    "}\n",
    "\n",
    "schema_valid = True\n",
    "for col, dtype in expected_schema.items():\n",
    "    if col not in df.columns:\n",
    "        print(f\"  ✗ Missing column: {col}\")\n",
    "        schema_valid = False\n",
    "    elif df[col].dtype != dtype:\n",
    "        print(f\"  ⚠ Column {col}: Expected {dtype}, got {df[col].dtype}\")\n",
    "\n",
    "if schema_valid:\n",
    "    print(\"  ✓ Schema validation PASSED\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Missing Value Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n[STEP 2] MISSING VALUE ANALYSIS\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "missing_summary = pd.DataFrame({\n",
    "    'Column': df.columns,\n",
    "    'Missing_Count': df.isnull().sum().values,\n",
    "    'Missing_Percentage': (df.isnull().sum() / len(df) * 100).values,\n",
    "    'Data_Type': df.dtypes.values\n",
    "})\n",
    "\n",
    "print(missing_summary.to_string(index=False))\n",
    "\n",
    "total_missing = df.isnull().sum().sum()\n",
    "if total_missing == 0:\n",
    "    print(\"\\n  ✓ No missing values detected\")\n",
    "else:\n",
    "    print(f\"\\n  ⚠ Total missing values: {total_missing}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Duplicate Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n[STEP 3] DUPLICATE DETECTION\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "# Check duplicate rows\n",
    "duplicate_rows = df.duplicated()\n",
    "dup_count = duplicate_rows.sum()\n",
    "\n",
    "# Check duplicate transaction IDs\n",
    "dup_ids = df['transaction_id'].duplicated()\n",
    "dup_id_count = dup_ids.sum()\n",
    "\n",
    "print(f\"  Duplicate Rows: {dup_count} ({dup_count/len(df)*100:.2f}%)\")\n",
    "print(f\"  Duplicate Transaction IDs: {dup_id_count}\")\n",
    "\n",
    "if dup_count > 0:\n",
    "    print(\"\\n  Duplicate Records:\")\n",
    "    print(df[duplicate_rows])\n",
    "else:\n",
    "    print(\"\\n  ✓ No duplicates detected\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Domain Constraint Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n[STEP 4] DOMAIN CONSTRAINT VALIDATION\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "validation_results = {}\n",
    "\n",
    "# Transaction Hour: 0-23\n",
    "invalid_hours = df[(df['transaction_hour'] < 0) | (df['transaction_hour'] > 23)]\n",
    "validation_results['transaction_hour'] = len(invalid_hours)\n",
    "print(f\"  transaction_hour (0-23): {len(invalid_hours)} invalid values\")\n",
    "\n",
    "# Device Trust Score: 0-100\n",
    "invalid_scores = df[(df['device_trust_score'] < 0) | (df['device_trust_score'] > 100)]\n",
    "validation_results['device_trust_score'] = len(invalid_scores)\n",
    "print(f\"  device_trust_score (0-100): {len(invalid_scores)} invalid values\")\n",
    "\n",
    "# Amount: positive\n",
    "invalid_amounts = df[df['amount'] <= 0]\n",
    "validation_results['amount'] = len(invalid_amounts)\n",
    "print(f\"  amount (>0): {len(invalid_amounts)} invalid values\")\n",
    "\n",
    "# Velocity: non-negative\n",
    "invalid_velocity = df[df['velocity_last_24h'] < 0]\n",
    "validation_results['velocity'] = len(invalid_velocity)\n",
    "print(f\"  velocity_last_24h (≥0): {len(invalid_velocity)} invalid values\")\n",
    "\n",
    "# Age: reasonable range\n",
    "invalid_age = df[(df['cardholder_age'] < 18) | (df['cardholder_age'] > 100)]\n",
    "validation_results['cardholder_age'] = len(invalid_age)\n",
    "print(f\"  cardholder_age (18-100): {len(invalid_age)} invalid values\")\n",
    "\n",
    "# Binary fields: 0 or 1\n",
    "binary_fields = ['foreign_transaction', 'location_mismatch', 'is_fraud']\n",
    "for field in binary_fields:\n",
    "    invalid_binary = df[~df[field].isin([0, 1])]\n",
    "    validation_results[field] = len(invalid_binary)\n",
    "    print(f\"  {field} (0/1): {len(invalid_binary)} invalid values\")\n",
    "\n",
    "total_invalid = sum(validation_results.values())\n",
    "if total_invalid == 0:\n",
    "    print(\"\\n  ✓ All domain constraints satisfied\")\n",
    "else:\n",
    "    print(f\"\\n  ⚠ Total domain violations: {total_invalid}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Outlier Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n[STEP 5] OUTLIER DETECTION\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "numerical_features = ['amount', 'transaction_hour', 'device_trust_score', \n",
    "                     'velocity_last_24h', 'cardholder_age']\n",
    "\n",
    "outlier_summary = []\n",
    "\n",
    "for feature in numerical_features:\n",
    "    # IQR Method\n",
    "    Q1 = df[feature].quantile(0.25)\n",
    "    Q3 = df[feature].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    \n",
    "    iqr_outliers = df[(df[feature] < lower_bound) | (df[feature] > upper_bound)]\n",
    "    \n",
    "    # Z-Score Method (threshold = 3)\n",
    "    z_scores = np.abs(stats.zscore(df[feature]))\n",
    "    z_outliers = df[z_scores > 3]\n",
    "    \n",
    "    outlier_summary.append({\n",
    "        'Feature': feature,\n",
    "        'IQR_Outliers': len(iqr_outliers),\n",
    "        'Z_Score_Outliers': len(z_outliers),\n",
    "        'Lower_Bound': lower_bound,\n",
    "        'Upper_Bound': upper_bound,\n",
    "        'Min': df[feature].min(),\n",
    "        'Max': df[feature].max()\n",
    "    })\n",
    "\n",
    "outlier_df = pd.DataFrame(outlier_summary)\n",
    "print(outlier_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Statistical Profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n[STEP 6] STATISTICAL PROFILING\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "numerical_features = ['amount', 'transaction_hour', 'device_trust_score', \n",
    "                     'velocity_last_24h', 'cardholder_age']\n",
    "\n",
    "stats_profile = df[numerical_features].describe(\n",
    "    percentiles=[.01, .05, .25, .5, .75, .95, .99]\n",
    ").T\n",
    "\n",
    "# Add additional statistics\n",
    "stats_profile['skewness'] = df[numerical_features].skew()\n",
    "stats_profile['kurtosis'] = df[numerical_features].kurtosis()\n",
    "stats_profile['cv'] = stats_profile['std'] / stats_profile['mean']\n",
    "\n",
    "print(\"\\nNumerical Features Profile:\")\n",
    "print(stats_profile.round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7: Target Variable Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n[STEP 7] TARGET VARIABLE ANALYSIS\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "fraud_dist = df['is_fraud'].value_counts().sort_index()\n",
    "fraud_pct = df['is_fraud'].value_counts(normalize=True).sort_index() * 100\n",
    "\n",
    "print(\"\\nTarget Variable Distribution:\")\n",
    "print(f\"  Normal (0): {fraud_dist.get(0, 0)} ({fraud_pct.get(0, 0):.2f}%)\")\n",
    "print(f\"  Fraud (1):  {fraud_dist.get(1, 0)} ({fraud_pct.get(1, 0):.2f}%)\")\n",
    "\n",
    "if 1 in fraud_dist.index and 0 in fraud_dist.index:\n",
    "    imbalance_ratio = fraud_dist[0] / fraud_dist[1]\n",
    "    print(f\"\\n  Imbalance Ratio: {imbalance_ratio:.2f}:1\")\n",
    "    \n",
    "    if imbalance_ratio > 10:\n",
    "        print(\"  ⚠ HIGH IMBALANCE - Consider resampling techniques\")\n",
    "    elif imbalance_ratio > 5:\n",
    "        print(\"  ⚠ MODERATE IMBALANCE - Monitor model performance\")\n",
    "    else:\n",
    "        print(\"  ✓ ACCEPTABLE BALANCE\")\n",
    "elif 1 not in fraud_dist.index:\n",
    "    print(\"\\n  ⚠ CRITICAL: No fraud cases in dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 8: Categorical Feature Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n[STEP 8] CATEGORICAL FEATURE ANALYSIS\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "# Merchant Category\n",
    "merchant_dist = df['merchant_category'].value_counts()\n",
    "merchant_pct = df['merchant_category'].value_counts(normalize=True) * 100\n",
    "\n",
    "print(\"\\nMerchant Category Distribution:\")\n",
    "for cat, count in merchant_dist.items():\n",
    "    print(f\"  {cat:15s}: {count:4d} ({merchant_pct[cat]:5.2f}%)\")\n",
    "\n",
    "print(f\"\\n  Total unique categories: {df['merchant_category'].nunique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 9: Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n[STEP 9] CORRELATION ANALYSIS\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "numerical_cols = ['amount', 'transaction_hour', 'device_trust_score', \n",
    "                 'velocity_last_24h', 'cardholder_age', \n",
    "                 'foreign_transaction', 'location_mismatch', 'is_fraud']\n",
    "\n",
    "corr_matrix = df[numerical_cols].corr()\n",
    "\n",
    "print(\"\\nCorrelation with Target Variable (is_fraud):\")\n",
    "target_corr = corr_matrix['is_fraud'].sort_values(ascending=False)\n",
    "for feature, corr_val in target_corr.items():\n",
    "    if feature != 'is_fraud':\n",
    "        print(f\"  {feature:25s}: {corr_val:7.4f}\")\n",
    "\n",
    "# High correlations between features (multicollinearity check)\n",
    "print(\"\\nHigh Feature Correlations (|r| > 0.7):\")\n",
    "high_corr_pairs = []\n",
    "for i in range(len(corr_matrix.columns)):\n",
    "    for j in range(i+1, len(corr_matrix.columns)):\n",
    "        if abs(corr_matrix.iloc[i, j]) > 0.7:\n",
    "            high_corr_pairs.append((\n",
    "                corr_matrix.columns[i],\n",
    "                corr_matrix.columns[j],\n",
    "                corr_matrix.iloc[i, j]\n",
    "            ))\n",
    "\n",
    "if high_corr_pairs:\n",
    "    for feat1, feat2, corr_val in high_corr_pairs:\n",
    "        print(f\"  {feat1} <-> {feat2}: {corr_val:.4f}\")\n",
    "else:\n",
    "    print(\"  ✓ No multicollinearity detected\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Quality Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"DATA QUALITY SCORECARD\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "total_records = len(df)\n",
    "total_features = len(df.columns) - 1  # Excluding target\n",
    "\n",
    "# Calculate quality score\n",
    "missing_values = df.isnull().sum().sum()\n",
    "duplicates = df.duplicated().sum()\n",
    "domain_violations = sum(validation_results.values())\n",
    "\n",
    "quality_scores = {\n",
    "    'Completeness': 100 if missing_values == 0 else \n",
    "                  (1 - missing_values / (total_records * total_features)) * 100,\n",
    "    'Uniqueness': 100 if duplicates == 0 else\n",
    "                 (1 - duplicates / total_records) * 100,\n",
    "    'Validity': 100 if domain_violations == 0 else 95,\n",
    "}\n",
    "\n",
    "overall_quality = np.mean(list(quality_scores.values()))\n",
    "\n",
    "print(f\"\\nDataset Size: {total_records} records × {total_features + 1} features\")\n",
    "print(f\"\\nQuality Dimensions:\")\n",
    "for dimension, score in quality_scores.items():\n",
    "    status = \"✓\" if score >= 95 else \"⚠\"\n",
    "    print(f\"  {status} {dimension:15s}: {score:6.2f}%\")\n",
    "\n",
    "print(f\"\\n{'='*40}\")\n",
    "print(f\"  Overall Quality Score: {overall_quality:.2f}%\")\n",
    "print(f\"{'='*40}\")\n",
    "\n",
    "# Quality grade\n",
    "if overall_quality >= 95:\n",
    "    grade = \"EXCELLENT\"\n",
    "elif overall_quality >= 85:\n",
    "    grade = \"GOOD\"\n",
    "elif overall_quality >= 70:\n",
    "    grade = \"FAIR\"\n",
    "else:\n",
    "    grade = \"POOR\"\n",
    "\n",
    "print(f\"\\n  Data Quality Grade: {grade}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Exploratory Data Analysis\n",
    "### Univariate Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"UNIVARIATE ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "numerical_features = ['amount', 'transaction_hour', 'device_trust_score', \n",
    "                     'velocity_last_24h', 'cardholder_age']\n",
    "\n",
    "for feature in numerical_features:\n",
    "    print(f\"\\n{feature.upper()}\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    # Descriptive statistics\n",
    "    print(f\"  Mean:       {df[feature].mean():.2f}\")\n",
    "    print(f\"  Median:     {df[feature].median():.2f}\")\n",
    "    print(f\"  Std Dev:    {df[feature].std():.2f}\")\n",
    "    print(f\"  Range:      [{df[feature].min():.2f}, {df[feature].max():.2f}]\")\n",
    "    print(f\"  IQR:        {df[feature].quantile(0.75) - df[feature].quantile(0.25):.2f}\")\n",
    "    \n",
    "    # Distribution shape\n",
    "    skew = df[feature].skew()\n",
    "    kurt = df[feature].kurtosis()\n",
    "    print(f\"  Skewness:   {skew:.3f} {'(Right-skewed)' if skew > 0 else '(Left-skewed)' if skew < 0 else '(Symmetric)'}\")\n",
    "    print(f\"  Kurtosis:   {kurt:.3f} {'(Heavy-tailed)' if kurt > 0 else '(Light-tailed)'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bivariate Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"BIVARIATE ANALYSIS (Features vs Fraud)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "if df['is_fraud'].nunique() < 2:\n",
    "    print(\"\\n  ⚠ Cannot perform bivariate analysis - only one class present\")\n",
    "else:\n",
    "    numerical_features = ['amount', 'transaction_hour', 'device_trust_score', \n",
    "                         'velocity_last_24h', 'cardholder_age']\n",
    "    \n",
    "    for feature in numerical_features:\n",
    "        print(f\"\\n{feature.upper()} by Fraud Status:\")\n",
    "        print(\"-\" * 40)\n",
    "        \n",
    "        fraud_stats = df.groupby('is_fraud')[feature].describe()\n",
    "        print(fraud_stats)\n",
    "        \n",
    "        # Statistical test (Mann-Whitney U)\n",
    "        normal_vals = df[df['is_fraud'] == 0][feature]\n",
    "        fraud_vals = df[df['is_fraud'] == 1][feature]\n",
    "        \n",
    "        if len(fraud_vals) > 0:\n",
    "            stat, p_value = mannwhitneyu(normal_vals, fraud_vals)\n",
    "            print(f\"\\n  Mann-Whitney U test p-value: {p_value:.4f}\")\n",
    "            if p_value < 0.05:\n",
    "                print(f\"  ✓ Significant difference between groups\")\n",
    "            else:\n",
    "                print(f\"  ✗ No significant difference\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multivariate Pattern Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"MULTIVARIATE PATTERN ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Amount by merchant and fraud\n",
    "print(\"\\nAverage Amount by Merchant Category:\")\n",
    "merchant_amount = df.groupby('merchant_category')['amount'].agg(['mean', 'std', 'count'])\n",
    "print(merchant_amount.round(2))\n",
    "\n",
    "# Risk factor combinations\n",
    "print(\"\\nRisk Factor Combinations:\")\n",
    "risk_analysis = df.groupby(['foreign_transaction', 'location_mismatch']).agg({\n",
    "    'is_fraud': ['count', 'sum', 'mean'],\n",
    "    'amount': 'mean',\n",
    "    'device_trust_score': 'mean'\n",
    "}).round(2)\n",
    "print(risk_analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Importance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FEATURE IMPORTANCE INDICATORS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "numerical_features = ['amount', 'transaction_hour', 'device_trust_score', \n",
    "                     'velocity_last_24h', 'cardholder_age']\n",
    "\n",
    "# Variance-based\n",
    "print(\"\\nFeature Variance (Higher = More Informative):\")\n",
    "for feature in numerical_features:\n",
    "    var = df[feature].var()\n",
    "    cv = df[feature].std() / df[feature].mean() if df[feature].mean() != 0 else 0\n",
    "    print(f\"  {feature:25s}: Variance={var:10.2f}, CV={cv:.4f}\")\n",
    "\n",
    "# Information value (if fraud cases exist)\n",
    "if df['is_fraud'].sum() > 0:\n",
    "    print(\"\\nPreliminary Feature-Target Association:\")\n",
    "    for feature in numerical_features:\n",
    "        corr = df[feature].corr(df['is_fraud'])\n",
    "        print(f\"  {feature:25s}: r={corr:7.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Executive Summary & Save Cleaned Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"EXECUTIVE SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\n✓ Data Cleaning Completed\")\n",
    "print(f\"✓ Exploratory Data Analysis Completed\")\n",
    "print(f\"✓ Data Quality Score: {overall_quality:.2f}%\")\n",
    "print(f\"✓ Ready for Feature Engineering & Modeling\")\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "\n",
    "# Save cleaned data\n",
    "df.to_csv(output_filepath, index=False)\n",
    "print(f\"\\n✓ Cleaned data saved to: {output_filepath}\")\n",
    "print(f\"✓ Total records saved: {len(df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Quick Data Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display first few rows\n",
    "print(\"\\nFirst 5 rows of cleaned data:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display basic info\n",
    "print(\"\\nDataset Information:\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display statistical summary\n",
    "print(\"\\nStatistical Summary:\")\n",
    "df.describe()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
